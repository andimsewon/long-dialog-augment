{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12ea007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfc3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLLM ì„œë²„ ì£¼ì†Œ\n",
    "llama_api_url = \"http://114.70.193.164:8001/v1/completions\"\n",
    "\n",
    "# ì…ë ¥ ë° ì¶œë ¥ íŒŒì¼\n",
    "input_file = Path(\"data/K2-00001-CL33762-CP33206-05-08-S2.json\")\n",
    "output_file = Path(\"outputs/augmented/K2-00001-augmented.json\")\n",
    "\n",
    "# ì¦ê°• ì£¼ì œ\n",
    "topic = \"í¸ì§€\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e04c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a553d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(data, topic):\n",
    "    persona1 = data[\"participantsInfo\"][\"speaker1\"]\n",
    "    persona2 = data[\"participantsInfo\"][\"speaker2\"]\n",
    "    utterances = data[\"utterances\"]\n",
    "\n",
    "    history = \"\"\n",
    "    for utt in utterances:\n",
    "        speaker = \"A\" if utt[\"speaker\"] == \"speaker1\" else \"B\"\n",
    "        history += f\"{speaker}: {utt['utterance']}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"You are a Korean conversation assistant.\n",
    "Your job is to continue the following two-person conversation on the topic '{topic}'.\n",
    "\n",
    "Persona A: {persona1}\n",
    "Persona B: {persona2}\n",
    "\n",
    "Conversation so far:\n",
    "{history}\n",
    "Please add 3~4 more turns in Korean that naturally continue the conversation.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e79dcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'utterances'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m prompt_input = \u001b[43mbuild_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m final_input = (\n\u001b[32m      4\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<|eot_id|><|start_header_id|>user<|end_header_id|>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m<|eot_id|>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<|start_header_id|>assistant<|end_header_id|>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mbuild_prompt\u001b[39m\u001b[34m(data, topic)\u001b[39m\n\u001b[32m      2\u001b[39m persona1 = data[\u001b[33m\"\u001b[39m\u001b[33mparticipantsInfo\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mspeaker1\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m persona2 = data[\u001b[33m\"\u001b[39m\u001b[33mparticipantsInfo\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mspeaker2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m utterances = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutterances\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m history = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m utt \u001b[38;5;129;01min\u001b[39;00m utterances:\n",
      "\u001b[31mKeyError\u001b[39m: 'utterances'"
     ]
    }
   ],
   "source": [
    "prompt_input = build_prompt(raw_data, topic)\n",
    "\n",
    "final_input = (\n",
    "    f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are a helpful assistant.\"\n",
    "    f\"<|eot_id|><|start_header_id|>user<|end_header_id|>{prompt_input}<|eot_id|>\"\n",
    "    f\"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4\",\n",
    "    \"prompt\": final_input,\n",
    "    \"max_tokens\": 512\n",
    "}\n",
    "\n",
    "response = requests.post(llama_api_url, json=payload, headers=headers)\n",
    "response.status_code, response.text[:300]  # ì‘ë‹µ ìƒíƒœ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0739a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    result_text = response.json()[\"choices\"][0][\"text\"]\n",
    "    print(\"ğŸ” ìƒì„±ëœ ì‘ë‹µ:\\n\", result_text)\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ ê¸°ì¡´ JSONì— ì¶”ê°€\n",
    "    raw_data[\"augmented_response\"] = result_text\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ ìƒì„± í›„ ì €ì¥\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(raw_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "else:\n",
    "    print(\"âŒ ìš”ì²­ ì‹¤íŒ¨:\", response.status_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
